
install.packages("dplyr")
install.packages("readr")
install.packages("stringr")
install.packages("tidyr")
install.packages("lubridate")
install.packages("textclean")
install.packages("tm")
install.packages("SnowballC")
install.packages("textstem")
install.packages("tidytext")
install.packages("ggplot2")
install.packages("wordcloud")
install.packages("RColorBrewer")
library(dplyr)
library(readr)
library(stringr)
library(tidyr)
library(lubridate)
library(textclean)
library(tm)
library(SnowballC)
library(textstem)
library(tidytext)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
df <- read_csv("E:/Data Science/Hotel_Reviews.csv")
df <- df %>% select(Hotel_Address, Hotel_Name, Review_Date, Review)
df <- df %>% slice(1:10000)
write_csv(df, "E:/Data Science/Hotel_reviews_filtered.csv")
View(df)
df <- read_csv("E:/Data Science/Hotel_reviews_filtered.csv")
df <- df %>% filter(!is.na(Review))
print(head(df %>% select(Hotel_Name, Review), 5))
df <- df %>% mutate(text_contracted = replace_contraction(Review))
print(head(df %>% select(text_contracted), 5))
df <- df %>% mutate(text_cleaned = replace_emoji(text_contracted), text_cleaned = replace_emoticon(text_cleaned))
print(head(df %>% select(text_contracted, text_cleaned), 5))
clean_text <- function(text) {
  text <- tolower(text)
  text <- gsub("<.*?>", " ", text)
  text <- gsub("[^a-z\\s]", " ", text)
  text <- gsub("\\s+", " ", text)
  text <- str_trim(text)
  return(text)
}
df <- df %>% mutate(text_cleaned_final = sapply(text_cleaned, clean_text))
print(head(df %>% select(text_cleaned_final), 5))
data("stop_words")
df$id <- 1:nrow(df)
tokens_filtered <- df %>% select(id, text_cleaned_final) %>% unnest_tokens(word, text_cleaned_final) %>% filter(!word %in% stop_words$word) %>% filter(nchar(word) > 2) %>% group_by(id) %>% summarise(tokens = list(word), .groups = "drop")
df <- df %>% left_join(tokens_filtered, by = "id")
print(head(df %>% select(text_cleaned_final, tokens), 5))
df <- df %>% mutate(tokens_lemmatized = lapply(tokens, lemmatize_words), tokens_stemmed = lapply(tokens_lemmatized, stem_words))
print(head(df %>% select(tokens, tokens_lemmatized, tokens_stemmed), 2))
df <- df %>% mutate(final_text = sapply(tokens_stemmed, function(x) paste(x, collapse = " ")))
print(head(df %>% select(final_text), 5))
df <- df %>% mutate(Review_Date = parse_date_time(Review_Date, orders = c("dmy", "mdy", "ymd"), tz = "UTC")) %>% mutate(Review_Date = format(Review_Date, "%d-%B-%Y"))
print(head(df %>% select(Review_Date), 5))
write_csv(df %>% select(Hotel_Address, Hotel_Name, Review_Date, Review, final_text), "E:/Data Science/processed_hotel_reviews.csv")
View(df)
df <- read_csv("E:/Data Science/processed_hotel_reviews.csv")
corpus <- Corpus(VectorSource(df$final_text))
dtm_tfidf <- DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf, wordLengths = c(3, Inf)))
print(dtm_tfidf)
inspect(dtm_tfidf[1:5, 1:10])
saveRDS(dtm_tfidf, "E:/Data Science/TFIDF_matrix.rds")
install.packages("dbscan")
library(dbscan)
install.packages("sentimentr")
library(sentimentr)
install.packages("factoextra")
library(factoextra)
library(cluster)
library(factoextra)
library(dbscan)
install.packages("Rtsne")
library(Rtsne)
library(readr)
library(ggplot2)
library(ggrepel)
library(factoextra)
library(dbscan)
library(Rtsne)
dtm_tfidf <- readRDS("E:/Data Science/TFIDF_matrix.rds")
m <- as.matrix(dtm_tfidf)
df <- read_csv("E:/Data Science/processed_hotel_reviews.csv")
m_5000 <- m[1:5000, ]
df_5000 <- df[1:5000, ]
m_5000 <- m_5000[, apply(m_5000, 2, var) > 0]
set.seed(123)
m_pca <- prcomp(m_5000, center = TRUE, scale. = TRUE)
n_comp <- min(50, ncol(m_pca$x))
m_reduced <- m_pca$x[, 1:n_comp]
unique_idx <- !duplicated(m_reduced)
m_reduced_nodup <- m_reduced[unique_idx, ]
set.seed(123)
tsne_res <- Rtsne(m_reduced_nodup, dims = 2, perplexity = 30, verbose = TRUE, max_iter = 500)
tsne_data <- tsne_res$Y
tsne_full <- tsne_data[cumsum(unique_idx), ]
colnames(tsne_full) <- c("X1", "X2")
k <- 3
map_labels <- function(x) { factor(x, levels = 1:3, labels = c("Positive", "Negative", "Mixed")) }
set.seed(123)
km_res <- kmeans(tsne_full, centers = k, nstart = 25)
km_labels <- map_labels(km_res$cluster)
km_df <- data.frame(tsne_full, cluster = km_labels)
ggplot(km_df, aes(x = X1, y = X2, color = cluster, label = cluster)) + geom_point(size = 1.2, alpha = 0.6) + geom_text_repel(size = 2, show.legend = FALSE) + labs(title = "K-Means Clustering (Positive / Negative / Mixed)", x = "Dim 1", y = "Dim 2") + theme_minimal()
dist_mat <- dist(tsne_full, method = "euclidean")
hc <- hclust(dist_mat, method = "ward.D2")
hc_clusters <- cutree(hc, k = k)
hc_labels <- map_labels(hc_clusters)
hc_df <- data.frame(tsne_full, cluster = hc_labels)
ggplot(hc_df, aes(x = X1, y = X2, color = cluster, label = cluster)) + geom_point(size = 1.2, alpha = 0.6) + geom_text_repel(size = 2, show.legend = FALSE) + labs(title = "Hierarchical Clustering (Positive / Negative / Mixed)", x = "Dim 1", y = "Dim 2") + theme_minimal()
db_res <- dbscan(tsne_full, eps = 2, minPts = 5)
db_labels <- ifelse(db_res$cluster == 0, "Mixed", ifelse(db_res$cluster %% 3 == 1, "Positive", ifelse(db_res$cluster %% 3 == 2, "Negative", "Mixed")))
db_labels <- as.factor(db_labels)
db_df <- data.frame(tsne_full, cluster = db_labels)
ggplot(db_df, aes(x = X1, y = X2, color = cluster, label = cluster)) + geom_point(size = 1.2, alpha = 0.6) + geom_text_repel(size = 2, show.legend = FALSE) + labs(title = "DBSCAN Clustering (Positive / Negative / Mixed)", x = "Dim 1", y = "Dim 2") + theme_minimal()
results <- data.frame(Document = 1:nrow(tsne_full), Review = df_5000$final_text, KMeans_Cluster = km_labels, Hierarchical_Cluster = hc_labels, DBSCAN_Cluster = db_labels)
write.csv(results, "C:/Users/dipan/Desktop/9th Semester/Data Science/project/clustered_results_5000.csv", row.names = FALSE)
print(table(km_labels))
print(table(hc_labels))
print(table(db_labels))
library(tidytext)
cluster_words <- data.frame(Review=df_5000$final_text, Cluster=km_labels) %>% unnest_tokens(word, Review) %>% anti_join(stop_words) %>% count(Cluster, word, sort=TRUE) %>% group_by(Cluster) %>% slice_max(n, n=10)
ggplot(cluster_words, aes(x=reorder_within(word, n, Cluster), y=n, fill=Cluster)) + geom_col(show.legend=FALSE) + facet_wrap(~Cluster, scales="free") + scale_x_reordered() + labs(title="Top 10 Words per Cluster", x="Word", y="Count")
library(cluster)
sil <- silhouette(km_res$cluster, dist(tsne_full))
fviz_silhouette(sil)
```